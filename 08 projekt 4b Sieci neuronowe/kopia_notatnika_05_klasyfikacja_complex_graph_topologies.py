# -*- coding: utf-8 -*-
"""Kopia notatnika 05 klasyfikacja_complex graph topologies.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eRnZJ_G7R4Qdyucle3rbA1-ZigDDcXj2
"""

# Importowanie potrzebnych bibliotek i modułów
import numpy as np
import matplotlib.pyplot as plt

from sklearn.datasets import make_moons
from sklearn.model_selection import train_test_split
#from sklearn.metrics import accuracy_score

import keras
from keras import layers

# Tworzenie zbioru danych
X, y = make_moons(n_samples=10000, noise=0.4, random_state=42)
# Podział danych na zbiory uczący i testowy
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train_1, X_train_2 = np.split(X_train, 2, axis=1)
X_test_1, X_test_2 = np.split(X_test, 2, axis=1)

# Tworzenie modelu sieci neuronowej
input_X1 = '''do uzupelnienia'''
dense_layer_1_X1 = '''do uzupelnienia'''
dense_layer_2_X1 = '''do uzupelnienia'''

input_X2 = '''do uzupelnienia'''
dense_layer_1_X2 = '''do uzupelnienia'''

# Łącz wszystkie dostępne cechy w pojedynczy, duży wektor.
concatenate_layer = '''do uzupelnienia'''

dense_layer_X1X2 = '''do uzupelnienia'''

outputs = '''do uzupelnienia'''

model = keras.Model(inputs=[input_X1,input_X2], outputs=outputs, name="fun_API")

# wizualizacja modelu
model.summary()
keras.utils.plot_model(model, "my_first_model.png",show_shapes=True)

# Kompilacja modelu
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Trenowanie modelu
history = model.fit([X_train_1,X_train_2], y_train, epochs=1000, batch_size=100, validation_data=([X_test_1,X_test_2], y_test), verbose='0')

# Ocena modelu na danych testowych
_, test_accuracy = model.evaluate([X_test_1,X_test_2], y_test)
_, train_accuracy = model.evaluate([X_train_1,X_train_2], y_train)

# Rysowanie granicy decyzyjnej dla sieci neuronowej
plt.figure(figsize=(8, 6))
# Rysowanie punktów danych treningowych
plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, marker='.', label='Train')
# Rysowanie punktów danych testowych
plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, marker='x', label='Test')

# Tworzenie siatki punktów dla wykresu konturu decyzji
xx, yy = np.meshgrid(np.linspace(X[:, 0].min() - 1, X[:, 0].max() + 1, 100),
                     np.linspace(X[:, 1].min() - 1, X[:, 1].max() + 1, 100))

# Obliczanie wyników dla wszystkich punktów siatki jednocześnie
temp = model.predict([xx.reshape((xx.shape[0]*xx.shape[1], 1)), yy.reshape((yy.shape[0]*yy.shape[1], 1))])
Z = np.round(temp).reshape(xx.shape)

# Rysowanie granicy decyzyjnej na wykresie konturu
plt.contourf(xx, yy, Z, alpha=0.3)

# Ustawienie tytułu wykresu
plt.title(f"Neural Network\nTest accuracy: {test_accuracy:.3f} and train accuracy: {train_accuracy:.3f}")
# Dodanie legendy
plt.legend()
# Wyświetlenie wykresu
plt.tight_layout()
plt.show()

# Wykres MSE vs epoki
plt.plot(history.history['loss'], label='binary_crossentropy')
plt.title('binary_crossentropy vs Epochs')
plt.ylabel('crossentropy')
plt.xlabel('Epoch')
plt.legend(loc="upper right")
plt.show()

# Wykres MSE vs epoki
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy vs Epochs')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(loc="lower right")
plt.show()