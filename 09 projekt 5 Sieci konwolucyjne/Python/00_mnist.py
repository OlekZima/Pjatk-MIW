# -*- coding: utf-8 -*-
"""00_mnist.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uyh_6V18B0mCTA5rUYjQ-oSZRomGCLGp
"""

import numpy as np
import keras
import matplotlib.pyplot as plt
from keras.models import Model
from keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D
from keras.utils import plot_model
from keras.datasets import mnist

# Załaduj dane
(x_train,y_train), (x_test, y_test) = mnist.load_data()
# podgląd
print("etykieta ",y_train[0])
plt.imshow(x_train[0], cmap='gray')

# Przetwórz dane
# Dane typu float32, modele często lepiej radzą sobie z danymi liczbowymi w formie zmiennoprzecinkowej.
# Normalizujemy dane do przedziału [0, 1]
x_train = '''do uzupełnienia'''
x_test = '''do uzupełnienia'''

# Konwertuj etykiety na kategorie
# kodowanie kategoryczne (one-hot encoding) na zbiorze etykiet treningowych
# zamienia etykiety klas na postać binarną w formie wektorów zer i jedynek
# 3 -> [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]
num_classes = '''do uzupełnienia'''
y_train = '''do uzupełnienia'''
y_test = '''do uzupełnienia'''

# Zdefiniuj model za pomocą Functional API
# Conv2D(liczba filtrów,...)
input_shape = '''do uzupełnienia'''
inputs = '''do uzupełnienia'''
x = '''do uzupełnienia'''
x = '''do uzupełnienia'''
x = '''do uzupełnienia'''
x = '''do uzupełnienia'''
outputs = '''do uzupełnienia'''
model = '''do uzupełnienia'''

# Skompiluj model
# 'categorical_crossentropy' średnia z logarytmu przewidywanych prawdopodobieństw dla prawdziwej klasy
# Optymalizator Adam (Adaptive Moment Estimation) wykorzystuje adaptacyjne momenty gradientu do efektywnego dostosowywania wag modelu podczas treningu
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
# Trenuj model
# batch_size liczba próbek treningowych użytych do jednej aktualizacji wag modelu podczas jednej iteracji treningowej
model.fit(x_train, y_train, batch_size=128, epochs=5, verbose='auto', validation_data=(x_test, y_test))

# Ocena modelu
loss, accuracy = model.evaluate(x_test, y_test, verbose='auto')
print('Test loss:', loss)
print('Test accuracy:', accuracy)

# Wizualizacja modelu
model.summary()
plot_model(model, show_shapes=True, show_layer_names=True)# to_file='model_plot.png',

# Wyświetlanie przykładów źle sklasyfikowanych
predictions = model.predict(x_test)
incorrect_indices = np.nonzero(np.argmax(predictions, axis=1) != np.argmax(y_test, axis=1))[0]

for i in range(5):
    idx = incorrect_indices[i]
    print("Przykład źle sklasyfikowany nr", i+1)
    plt.imshow(x_test[idx], cmap='gray')
    plt.xlabel(f"True label: {np.argmax(y_test[idx])}, Predicted label: {np.argmax(predictions[idx])}")
    plt.show()